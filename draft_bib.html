</dt-appendix>
</body>
<script type="text/bibliography">

% QT-Opt "arm-farm"
@misc{kalashnikov2018qsd,
     author    = {Dmitry Kalashnikov and Alex Irpan and Peter Pastor and Julian Ibarz and Alexander Herzog and Eric Jang and Deirdre Quillen and Ethan Holly and Mrinal Kalakrishnan and Vincent Vanhoucke and Sergey Levine},
     title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
     archivePrefix = {arXiv},
     eprint        = {1806.10293v2},
     year      = {2018}
}

@inproceedings{singh2009rewards,
  title={Where do rewards come from},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  booktitle={Proceedings of the annual conference of the cognitive science society},
  pages={2601--2606},
  year={2009}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}


@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

% matching game
@article{lazaridou2016mce,
  title={Multi-agent cooperation and the emergence of (natural) language},
  author={Lazaridou, Angeliki and Peysakhovich, Alexander and Baroni, Marco},
  journal={arXiv preprint arXiv:1612.07182},
  year={2016}
}

@inproceedings{mordatch2018egc,
    author = "Igor Mordatch and Pieter Abbeel",
    title = "Emergence of Grounded Compositional Language in Multi-Agent Populations",
    booktitle = {Proc.~of the AAAI Conference on Artificial Intelligence (AAAI)},
    year      = {2018}
}

% RL as inference
@misc{levine2018rlc,
     author    = {Sergey Levine},
     title     = {Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review},
     archivePrefix = {arXiv},
     eprint        = {1805.00909},
     year      = {2018}
}

% chelsea's imitation learning from video demo
@inproceedings{yu2018osi,
  author    = {Tianhe Yu and Chelsea Finn and Annie Xie and Sudeep Dasari and Tianhao Zhang and Pieter Abbeel and Sergey Levine},
  title     = {One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning},
  booktitle = {Proc.~of Robotics: Science and Systems (RSS)},
  year      = {2018}
}

% few-shot imitation learning
@inproceedings{james2018tec,
  author    = {Stephen James and Michael Bloesch and Andrew J. Davison},
  title     = {Task-Embedded Control Networks for Few-Shot Imitation Learning},
  booktitle = {Proc.~of the Conference on Robot Learning (CoRL)},
  year      = {2018}
}

% coma
@inproceedings{foerster2018cma,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob N and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

% Neuralese
@article{andreas2017tn,
  title={Translating neuralese},
  author={Andreas, Jacob and Dragan, Anca and Klein, Dan},
  journal={arXiv preprint arXiv:1704.06960},
  year={2017}
}

% maddpg
@inproceedings{lowe2017maa,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6379--6390},
  year={2017}
}

@article{online_meta_learning,
  title={Online Meta-Learning},
  author={Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.08438},
  year={2019}
}

% Transformer
@inproceedings{vaswani2017aay,
  author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  title = {Attention Is All You Need},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS)},
  year = {2017}
}

% MAML
@inproceedings{finn2017mam,
  author    = {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  title     = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  booktitle = {Proc.~of the International Conference on Machine Learning (ICML)},
  year      = {2017}
}

% PILQR
@inproceedings{chebotar2017cmm,
  author    = {Yevgen Chebotar and Karol Hausman and Marvin Zhang and Gaurav Sukhatme and Stefan Schaal and Sergey Levine},
  title     = {Combining Model-Based and Model-Free Updates for Deep Reinforcement Learning},
  booktitle = {Proc.~of the International Conference on Machine Learning (ICML)},
  year      = {2017}
}

% auxiliary tasks
@inproceedings{jaderberg2017rlu,
  author    = {Max Jaderberg and Volodymyr Mnih and Wojciech Marian Czarnecki and Tom Schaul and Joel Z Leibo and David Silver and Koray Kavukcuoglu},
  title     = {Reinforcement Learning with Unsupervised Auxiliary Tasks},
  booktitle = {Proc.~of the International Conference on Learning Representations (ICLR)},
  year      = {2017}
}

% RL^2
@misc{duan2016rl2,
     author    = {Yan Duan and John Schulman and Xi Chen and Peter L. Bartlett and Ilya Sutskever and Pieter Abbeel},
     title     = {RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning},
     archivePrefix = {arXiv},
     eprint        = {1611.02779},
     year      = {2016}
}

@inproceedings{woodward2016aos,
     author    = {Mark Woodward and Chelsea Finn},
     title     = {Active One-shot Learning},
     booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS), Workshop on Deep Reinforcement Learning},
     year      = {2016}
}

@inproceedings{santoro2016osl,
  author    = {Adam Santoro and Sergey Bartunov and Matthew Botvinick and Daan Wierstra and Timothy P. Lillicrap},
  title     = {One-shot Learning with Memory-Augmented Neural Networks},
  booktitle = {Proc.~of the International Conference on Machine Learning (ICML)},
  year      = {2016}
}

% benchmarks for different rl agorithms
@inproceedings{duan2016bdr,
  author    = {Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel},
  title     = {Benchmarking Deep Reinforcement Learning for Continuous Control},
  booktitle = {Proc.~of the International Conference on Machine Learning (ICML)},
  year      = {2016}
}

% NAF
@inproceedings{gu20162016cdq,
  author    = {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  title     = {Continuous Deep Q-Learning with Model-based Acceleration},
  booktitle = {Proc.~of the International Conference on Machine Learning (ICML)},
  year      = {2016}
}

% MemN2N
@inproceedings{sukhbaatar2015eem,
  author = {Sainbayar Sukhbaatar and Arthur Szlam and Jason Weston and Rob Fergus},
  title = {End-To-End Memory Networks},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS), Workshop on Deep Learning},
  year = {2015}
}

% Adam
@inproceedings{kingma2015ams,
  author    = {Diederik P. Kingma and Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {Proc.~of the International Conference for Learning Representations (ICLR)},
  year      = {2015}
}

% DRQN
@inproceedings{hausknecht2015drq,
  author = {Matthew Hausknecht and Peter Stone},
  title = {Deep Recurrent Q-Learning for Partially Observable MDPs},
  booktitle = {AAAI Fall Symposium Series},
  year = {2015}
}

% DQN
@inproceedings{mnih2013pad,
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
  title = {Playing Atari with Deep Reinforcement Learning},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS), Workshop on Deep Learning},
  year = {2013}
}

% LSTM
@article{hochreiter1997lst,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Computation},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = {nov},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
 year = {1997},
}

% markov games, cite for partially observable markov games
@incollection{littman1994mgf,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

% foundational learning-to-learn, sammy and yashua bengio
@inproceedings{bengio1991lsl,
  author = {Yoshua Bengio and Samy Bengio and Jocelyn Cloutier},
  title = {Learning a synaptic learning rule},
  booktitle = {Proc.~of the International Joint Conference on Neural Networks (IJCNN)},
  year = {1991}
}

% Schmidhuber thesis
@phdthesis{schmidhuber1987eps,
 author = {J\"{u}rgen Schmidhuber},
 title = {Evolutionary Principles in Self-Referential Learning},
 school = {Institut f. Informatik, Tech. Univ. Munich},
 year = {1987}
}

@misc{xu2018lpi,
     author    = {Kelvin Xu and Ellis Ratner and Anca Dragan and Sergey Levine and Chelsea Finn},
     title     = {Learning a Prior over Intent via Meta-Inverse Reinforcement Learning},
     archivePrefix = {arXiv},
     eprint        = {1805.12573},
     year      = {2018}
}

@misc{borsa2017olr,
     author    = {Diana Borsa and Bilal Piot and Remi Munos and Olivier Pietquin},
     title     = {Observational Learning by Reinforcement Learning},
     archivePrefix = {arXiv},
     eprint        = {1706.06617},
     year      = {2017}
}

@inproceedings{hester2018dqd,
  author = {Todd Hester and Matej Vecerik and Olivier Pietquin and Marc Lanctot and Tom Schaul and Bilal Piot and Dan Horgan and John Quan and Andrew Sendonaris and Gabriel Dulac-Arnold and Ian Osband and John Agapiou and Joel Z. Leibo and Audrunas Gruslys},
  title = {Deep Q-learning from Demonstrations},
  booktitle = {AAAI},
  year = {2018}
}

@inproceedings{gupta2017cmc,
  author = {Jayesh K. Gupta and Maxim Egorov and Mykel Kochenderfer},
  title = {Cooperative Multi-agent Control Using Deep Reinforcement Learning},
  booktitle = {Proc.~of Autonomous Agents and Multiagent Systems (AAMAS)},
  year = {2017}
}

@inproceedings{brown2018raa,
  author = {Daniel S. Brown and Yuchen Cui and Scott Niekum},
  title = {Risk-Aware Active Inverse Reinforcement Learning},
  booktitle = {Proc.~of Conference on Robot Learning (CoRL)},
  year = {2018}
}

@inproceedings{foerster2016lcd,
  author = {Jakob N. Foerster and Yannis M. Assael and Nando de Freitas and Shimon Whiteson},
  title = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS)},
  year = {2016}
}

@article{potter1994cca,
 author = {Mitchell A. Potter and Kenneth A. De Jong},
 title = {A Cooperative Coevolutionary Approach to Function Optimization},
 journal = {The Third Parallel Problem Solving From Nature},
 pages = {249--257},
 publisher = {Springer-Verlag},
 year = {1994},
}

@inproceedings{palmer2018lma,
  author = {Gregory Palmer and Karl Tuyls and Daan Bloembergen and Rahul Savani},
  title = {Lenient Multi-Agent Deep Reinforcement Learning},
  booktitle = {Proc.~of Autonomous Agents and Multiagent Systems (AAMAS)},
  year = {2018}
}

@inproceedings{matignon2007hql,
  author = {Laetitia Matignon and Guillaume J. Laurent and Nadine Le Fort-Piat},
  title = {Hysteretic q-learning: an algorithm for decentralized reinforcement learning in cooperative multi-agent teams},
  booktitle = {Proc.~of the International Conference on Intelligent Robots and Systems (IROS)},
  year = {2007}
}

@inproceedings{hadfield2016cir,
  author = {Dylan Hadfield-Menell and Anca Dragan and Pieter Abbeel and Stuart Russell},
  title = {Cooperative Inverse Reinforcement Learning},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS)},
  year = {2016}
}

@misc{krening2018naa,
     author    = {Samantha Krening},
     title     = {Newtonian Action Advice: Integrating Human Verbal Instruction with Reinforcement Learning},
     archivePrefix = {arXiv},
     eprint        = {1804.0582},
     year      = {2018}
}

% HG-DAGGER
@misc{kelly2018hgd,
     author    = {Michael Kelly and Chelsea Sidrane and Katherine Driggs-Campbell and Mykel J. Kochenderfer},
     title     = {HG-DAgger: Interactive Imitation Learning with Human Experts},
     archivePrefix = {arXiv},
     eprint        = {1810.02890},
     year      = {2018}
}

% Deep TAMER
@inproceedings{warnell2018dti,
  title={Deep tamer: Interactive agent shaping in high-dimensional state spaces},
  author={Warnell, Garrett and Waytowich, Nicholas and Lawhern, Vernon and Stone, Peter},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

% rational agents choose efficient language structure
@article{peloquin2019irp,
  title={The interactions of rational, pragmatic agents lead to efficient language structure and use},
  author={Peloquin, Benjamin N. and Goodman, Noah D. and Frank, Michael C.},
  year={2019},
  journal={PsyArXiv}
}

% Deep COACH
@article{arumugam2019drl,
  title={Deep reinforcement learning from policy-dependent human feedback},
  author={Arumugam, Dilip and Lee, Jun Ki and Saskin, Sophie and Littman, Michael L},
  journal={arXiv preprint arXiv:1902.04257},
  year={2019}
}

@inproceedings{ross2011ari,
  author = {Stephane Ross and Geoffrey J. Gordon and J. Andrew Bagnell},
  title = {A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
  booktitle = {Proc.~of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year = {2011}
}

% sophie's kitchen
@inproceedings{thomaz2005rti,
  author = {Andrea Lockerd Thomaz and Guy Hoffman and and Cynthia Breazeal},
  title = {Real-Time Interactive Reinforcement Learning for Robots},
  booktitle = {AAAI},
  year = {2005}
}

@inproceedings{isbell2001cas,
  author = {Charles Lee Isbell and Christian R. Shelton and Michael Kearns and Satinder P. Singh and Peter Stone},
  title = {Cobot: A Social Reinforcement Learning Agent},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS)},
  year = {2001}
}

@inproceedings{dattari2018ilc,
  author = {Rodrigo Perez-Dattari and Carlos Celemin and Javier Ruiz-del-Solar and Jens Kober},
  title = {Interactive Learning with Corrective Feedback for Policies based on Deep Neural Networks},
  booktitle = {Proc.~of the International Symposium on Experimental Robotics (ISER)},
  year = {2018}
}

@inproceedings{mindermann2018air,
  author = {Soren Mindermann and Rohin Shah and Adam Gleave and Dylan Hadfield-Menell},
  title = {Active Inverse Reward Design},
  booktitle = {Proc.~of the ICML/IJCAI/AAMAS Workshop on Goals for Reinforcement Learning},
  year = {2018}
}

@inproceedings{ibarz2018rlh,
  author = {Borja Ibarz and Jan Leike and Tobias Pohlen and Geoffrey Irving and Shane Legg and Dario Amodei},
  title = {Reward learning from human preferences and demonstrations in Atari},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS)},
  year = {2018}
}

% preference learning
@inproceedings{christiano2017drl,
  author = {Paul Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
  title = {Deep Reinforcement Learning from Human Preferences},
  booktitle = {Proc.~of the Conference on Neural Information Processing Systems (NIPS)},
  year = {2017}
}

@article{schaal1999ilr,
 author = {Stefan Schaal},
 title = {Is Imitation Learning the Route to Humanoid Robots?},
 journal = {Trends in Cognitive Sciences},
 pages = {233--242},
 publisher = {},
 year = {1999},
}


@book{barto1998rli,
  author    = {Andrew Barto and Richard S. Sutton}, 
  title     = {Reinforcement Learning: An Introduction},
  publisher = {MIT Press},
  year      = {1998},
}

@book{bertsekas1996ndp,
  author    = {Dmitri P. Bertsekas and John N. Tsitsiklis}, 
  title     = {Neuro-Dynamic Programming},
  publisher = {Athena Scientific},
  year      = {1996},
}

@inproceedings{chebotar-hausman-zhang17icml,
  title={Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning},
  author={Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004},
  organization={ACM}
}

@book{thrun2012learningtolearn,
  title={Learning to learn},
  author={Thrun, Sebastian and Pratt, Lorien},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{wang2016learning,
  title={Learning to reinforcement learn},
  author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  journal={arXiv preprint arXiv:1611.05763},
  year={2016}
}

@inproceedings{duan2017one,
  title={One-shot imitation learning},
  author={Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly and Ho, OpenAI Jonathan and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
  booktitle={Advances in neural information processing systems},
  pages={1087--1098},
  year={2017}
}

@article{yu2018one,
  title={One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning},
  author={Yu, Tianhe and Finn, Chelsea and Xie, Annie and Dasari, Sudeep and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.01557},
  year={2018}
}

% Dueling Networks
@article{wang2015dna,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}

% CNN, ConvNet
@article{lecun1995cni,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua and others},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  number={10},
  pages={1995},
  year={1995}
}

% q-learning
@phdthesis{watkins1989ldr,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  school={King's College, Cambridge}
}
               
</script>
<script src="lib/blazy.js"></script>
<script>
  var bLazy = new Blazy({
    success: function(){
      updateCounter();
    }
  });
  var imageLoaded = 0;
  function updateCounter() {
    imageLoaded++;
    console.log("blazy image loaded: "+imageLoaded);
  }
</script>
